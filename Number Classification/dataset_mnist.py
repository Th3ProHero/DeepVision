# -*- coding: utf-8 -*-
"""DataSetMNISTipynb

Automatically generated by Colab.

Coded by: Mau Bautista


Original file is located at
    https://colab.research.google.com/drive/1Y6_tFKINmKSWtBHBaaiUTifFkF93bbXs

1.Dataset de imagenes MNIST
"""

import tensorflow as tf
import numpy as np
import cv2
from google.colab.patches import cv2_imshow

mnist = tf.keras.datasets.mnist

(x_train,y_train),(x_test,y_test)=mnist.load_data()

x_train.shape

cv2_imshow(cv2.resize(x_train[0],(100,100)))

y_train[0]

x_test.shape

"""\2.Dataset de caracteristicas con hog features"""

img=x_train[1]
def get_hog():
  winSize=img.shape
  blockSize=(8,8)
  blockStride=(2,2)
  cellSize=(4,4)
  nbins=9
  hog=cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)
  return hog
hog=get_hog()
hog.compute(img).shape

"""Calcular para cada imagen"""

def get_feature_dataset(x):
  features=[]

  for img in x:
    features.append(hog.compute(img))
  features=np.array(features)
  return features

features_train=get_feature_dataset(x_train)
features_test=get_feature_dataset(x_test)

features_train.shape

features_test.shape

"""3.Definicion e implementacion de la red neuronal +onehot labels"""

y_trainOneHot = tf.one_hot(y_train,np.max(y_train)+1)
y_testOneHot = tf.one_hot(y_test,np.max(y_train)+1)

y_trainOneHot[1]

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
import tensorflow as tf

def classifier(features_train):
    model = Sequential()

    # Define la forma de entrada usando Input
    model.add(Input(shape=(features_train.shape[1],)))
    model.add(Dense(200, activation='relu'))
    model.add(Dense(180, activation='relu'))
    model.add(Dense(150, activation='relu'))
    model.add(Dense(10, activation='softmax'))

    # Compila el modelo con el argumento correcto
    model.compile(
        loss='categorical_crossentropy',
        optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3)
    )

    return model

# Ejemplo de uso (asegúrate de que features_train esté definido)
model = classifier(features_train)
model.summary()

"""4.Calculo de la matrix de confusion"""

#Epocas, cuantas veces se le pasa el dataset, batch es cuantas muestras se van a tomar para calcular el gradiente, en este caso 100 imagenes para calcular el gradiente solo apra esas y actualizar los pesos.
#si hay datasets de teras, una forma de no cargar todo en memoria, es cargar pedazos osea batches, calculamos, y asi de manera secuencial.
model.fit(features_train,y_trainOneHot,epochs=10, batch_size=100)

#Evaluar el sistema
prediction_train=model.predict(features_train)
prediction_test=model.predict(features_test)

prediction_train.shape

prediction_train[0]

y_pred_train=np.argmax(prediction_train,1)
y_pred_test=np.argmax(prediction_test,1)

y_pred_train

errorTrain= 100*np.sum(y_pred_train!=y_train)/len(y_train)
errorTest= 100*np.sum(y_pred_test!=y_test)/len(y_test)
print("Error de entrenamiento:")
print(errorTrain,"%")
print("Error de prueba:")
print(errorTest,"%")

"""4:Matriz de confusion"""

#la matriz de confusion nos indica visualmente cuantos aciertos y fracasos se tienen con el dataset de prueba
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

conf_mat=confusion_matrix(y_test,y_pred_test)
conf_mat
disp=ConfusionMatrixDisplay(confusion_matrix=conf_mat)
disp.plot()

conf_mat_norm = np.round(100*conf_mat/np.sum(conf_mat,1),1)

disp2=ConfusionMatrixDisplay(confusion_matrix=conf_mat_norm)
disp2.plot()